{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "\n",
    "### 1. Import libraries and load data from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ethango/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/ethango/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data/DisasterResponse.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql_table('df',engine)\n",
    "X = df.message.values\n",
    "Y = df.iloc[:, 4:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct      1.0   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct      1.0   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct      1.0   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct      1.0   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct      1.0   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0      0.0    0.0          0.0           0.0               0.0  ...   \n",
       "1      0.0    0.0          1.0           0.0               0.0  ...   \n",
       "2      0.0    0.0          0.0           0.0               0.0  ...   \n",
       "3      1.0    0.0          1.0           0.0               1.0  ...   \n",
       "4      0.0    0.0          0.0           0.0               0.0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "1          0.0                   0.0              1.0     0.0    1.0   0.0   \n",
       "2          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "3          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "4          0.0                   0.0              0.0     0.0    0.0   0.0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0         0.0   0.0            0.0            0.0  \n",
       "1         0.0   0.0            0.0            0.0  \n",
       "2         0.0   0.0            0.0            0.0  \n",
       "3         0.0   0.0            0.0            0.0  \n",
       "4         0.0   0.0            0.0            0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    token = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for tok in token:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building a machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                                                                        ccp_alpha=0.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        max_samples=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=100,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=None,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For label related this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.02      0.05      2042\n",
      "         1.0       0.76      0.99      0.86      6546\n",
      "         2.0       0.10      0.02      0.03        61\n",
      "\n",
      "    accuracy                           0.75      8649\n",
      "   macro avg       0.41      0.34      0.31      8649\n",
      "weighted avg       0.66      0.75      0.66      8649\n",
      "\n",
      "For label request this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.99      0.91      7194\n",
      "         1.0       0.39      0.02      0.04      1455\n",
      "\n",
      "    accuracy                           0.83      8649\n",
      "   macro avg       0.61      0.51      0.47      8649\n",
      "weighted avg       0.76      0.83      0.76      8649\n",
      "\n",
      "For label offer this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8615\n",
      "         1.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           1.00      8649\n",
      "   macro avg       0.50      0.50      0.50      8649\n",
      "weighted avg       0.99      1.00      0.99      8649\n",
      "\n",
      "For label aid_related this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.89      0.72      5133\n",
      "         1.0       0.49      0.16      0.24      3516\n",
      "\n",
      "    accuracy                           0.59      8649\n",
      "   macro avg       0.55      0.52      0.48      8649\n",
      "weighted avg       0.56      0.59      0.53      8649\n",
      "\n",
      "For label medical_help this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96      7984\n",
      "         1.0       0.00      0.00      0.00       665\n",
      "\n",
      "    accuracy                           0.92      8649\n",
      "   macro avg       0.46      0.50      0.48      8649\n",
      "weighted avg       0.85      0.92      0.89      8649\n",
      "\n",
      "For label medical_products this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98      8242\n",
      "         1.0       0.00      0.00      0.00       407\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.91      0.95      0.93      8649\n",
      "\n",
      "For label search_and_rescue this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99      8415\n",
      "         1.0       0.25      0.00      0.01       234\n",
      "\n",
      "    accuracy                           0.97      8649\n",
      "   macro avg       0.61      0.50      0.50      8649\n",
      "weighted avg       0.95      0.97      0.96      8649\n",
      "\n",
      "For label security this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8479\n",
      "         1.0       0.00      0.00      0.00       170\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.96      0.98      0.97      8649\n",
      "\n",
      "For label military this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      8366\n",
      "         1.0       1.00      0.00      0.01       283\n",
      "\n",
      "    accuracy                           0.97      8649\n",
      "   macro avg       0.98      0.50      0.50      8649\n",
      "weighted avg       0.97      0.97      0.95      8649\n",
      "\n",
      "For label child_alone this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8649\n",
      "\n",
      "    accuracy                           1.00      8649\n",
      "   macro avg       1.00      1.00      1.00      8649\n",
      "weighted avg       1.00      1.00      1.00      8649\n",
      "\n",
      "For label water this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97      8127\n",
      "         1.0       0.08      0.00      0.00       522\n",
      "\n",
      "    accuracy                           0.94      8649\n",
      "   macro avg       0.51      0.50      0.49      8649\n",
      "weighted avg       0.89      0.94      0.91      8649\n",
      "\n",
      "For label food this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.94      7740\n",
      "         1.0       0.30      0.01      0.01       909\n",
      "\n",
      "    accuracy                           0.89      8649\n",
      "   macro avg       0.60      0.50      0.48      8649\n",
      "weighted avg       0.83      0.89      0.85      8649\n",
      "\n",
      "For label shelter this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95      7865\n",
      "         1.0       0.07      0.00      0.00       784\n",
      "\n",
      "    accuracy                           0.91      8649\n",
      "   macro avg       0.49      0.50      0.48      8649\n",
      "weighted avg       0.83      0.91      0.87      8649\n",
      "\n",
      "For label clothing this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8513\n",
      "         1.0       0.00      0.00      0.00       136\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.97      0.98      0.98      8649\n",
      "\n",
      "For label money this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8452\n",
      "         1.0       0.12      0.01      0.01       197\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.55      0.50      0.50      8649\n",
      "weighted avg       0.96      0.98      0.97      8649\n",
      "\n",
      "For label missing_people this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      8544\n",
      "         1.0       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.98      0.99      0.98      8649\n",
      "\n",
      "For label refugees this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      8319\n",
      "         1.0       0.00      0.00      0.00       330\n",
      "\n",
      "    accuracy                           0.96      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.93      0.96      0.94      8649\n",
      "\n",
      "For label death this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98      8255\n",
      "         1.0       0.00      0.00      0.00       394\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.91      0.95      0.93      8649\n",
      "\n",
      "For label other_aid this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93      7554\n",
      "         1.0       0.07      0.00      0.01      1095\n",
      "\n",
      "    accuracy                           0.87      8649\n",
      "   macro avg       0.47      0.50      0.47      8649\n",
      "weighted avg       0.77      0.87      0.81      8649\n",
      "\n",
      "For label infrastructure_related this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.97      8081\n",
      "         1.0       0.00      0.00      0.00       568\n",
      "\n",
      "    accuracy                           0.93      8649\n",
      "   macro avg       0.47      0.50      0.48      8649\n",
      "weighted avg       0.87      0.93      0.90      8649\n",
      "\n",
      "For label transport this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98      8247\n",
      "         1.0       0.20      0.00      0.00       402\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.58      0.50      0.49      8649\n",
      "weighted avg       0.92      0.95      0.93      8649\n",
      "\n",
      "For label buildings this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      8202\n",
      "         1.0       0.13      0.01      0.02       447\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.54      0.50      0.49      8649\n",
      "weighted avg       0.91      0.95      0.92      8649\n",
      "\n",
      "For label electricity this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8473\n",
      "         1.0       0.00      0.00      0.00       176\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.49      0.50      0.49      8649\n",
      "weighted avg       0.96      0.98      0.97      8649\n",
      "\n",
      "For label tools this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      8603\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.50      0.50      0.50      8649\n",
      "weighted avg       0.99      0.99      0.99      8649\n",
      "\n",
      "For label hospitals this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      8553\n",
      "         1.0       0.00      0.00      0.00        96\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.98      0.99      0.98      8649\n",
      "\n",
      "For label shops this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8607\n",
      "         1.0       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           1.00      8649\n",
      "   macro avg       0.50      0.50      0.50      8649\n",
      "weighted avg       0.99      1.00      0.99      8649\n",
      "\n",
      "For label aid_centers this is the result.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      8542\n",
      "         1.0       0.00      0.00      0.00       107\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.98      0.99      0.98      8649\n",
      "\n",
      "For label other_infrastructure this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      8263\n",
      "         1.0       0.00      0.00      0.00       386\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.91      0.95      0.93      8649\n",
      "\n",
      "For label weather_related this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.97      0.84      6256\n",
      "         1.0       0.64      0.13      0.22      2393\n",
      "\n",
      "    accuracy                           0.74      8649\n",
      "   macro avg       0.69      0.55      0.53      8649\n",
      "weighted avg       0.72      0.74      0.67      8649\n",
      "\n",
      "For label floods this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96      7940\n",
      "         1.0       0.29      0.00      0.01       709\n",
      "\n",
      "    accuracy                           0.92      8649\n",
      "   macro avg       0.60      0.50      0.48      8649\n",
      "weighted avg       0.87      0.92      0.88      8649\n",
      "\n",
      "For label storm this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95      7815\n",
      "         1.0       0.52      0.02      0.04       834\n",
      "\n",
      "    accuracy                           0.90      8649\n",
      "   macro avg       0.71      0.51      0.49      8649\n",
      "weighted avg       0.87      0.90      0.86      8649\n",
      "\n",
      "For label fire this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      8563\n",
      "         1.0       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.50      0.50      0.50      8649\n",
      "weighted avg       0.98      0.99      0.99      8649\n",
      "\n",
      "For label earthquake this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.96      7836\n",
      "         1.0       0.75      0.15      0.25       813\n",
      "\n",
      "    accuracy                           0.92      8649\n",
      "   macro avg       0.83      0.57      0.60      8649\n",
      "weighted avg       0.90      0.92      0.89      8649\n",
      "\n",
      "For label cold this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8482\n",
      "         1.0       0.00      0.00      0.00       167\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.96      0.98      0.97      8649\n",
      "\n",
      "For label other_weather this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      8226\n",
      "         1.0       0.00      0.00      0.00       423\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.90      0.95      0.93      8649\n",
      "\n",
      "For label direct_report this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.99      0.89      6987\n",
      "         1.0       0.33      0.01      0.03      1662\n",
      "\n",
      "    accuracy                           0.81      8649\n",
      "   macro avg       0.57      0.50      0.46      8649\n",
      "weighted avg       0.72      0.81      0.73      8649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Must convert to dataframe first\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred, columns = df.columns[4:])\n",
    "y_test = pd.DataFrame(y_test, columns = df.columns[4:])\n",
    "\n",
    "for i, var in enumerate(df.columns[4:]):\n",
    "    print(\"For label \" + var + \" this is the result.\")\n",
    "    print(classification_report(y_test.iloc[:,i], \n",
    "                                y_pred.iloc[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=<function tokenize at 0x7fbea85e0950>,\n",
       "                   vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                          ccp_alpha=0.0,\n",
       "                                                          class_weight=None,\n",
       "                                                          criterion='gini',\n",
       "                                                          max_depth=None,\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          max_samples=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=100,\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=None,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                         n_jobs=None))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=<function tokenize at 0x7fbea85e0950>,\n",
       "                 vocabulary=None),\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                        ccp_alpha=0.0,\n",
       "                                                        class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features='auto',\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        max_samples=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        n_estimators=100,\n",
       "                                                        n_jobs=None,\n",
       "                                                        oob_score=False,\n",
       "                                                        random_state=None,\n",
       "                                                        verbose=0,\n",
       "                                                        warm_start=False),\n",
       "                       n_jobs=None),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters = {\n",
    "    'tfidf__smooth_idf': [False, True],\n",
    "    'clf__estimator__n_estimators': [1,10,20,30],\n",
    "    'clf__estimator__n_jobs': [1,2,3],\n",
    "    \n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(...\n",
       "                                                                                               n_estimators=100,\n",
       "                                                                                               n_jobs=None,\n",
       "                                                                                               oob_score=False,\n",
       "                                                                                               random_state=None,\n",
       "                                                                                               verbose=0,\n",
       "                                                                                               warm_start=False),\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'clf__estimator__n_estimators': [1, 10, 20, 30],\n",
       "                         'clf__estimator__n_jobs': [1, 2, 3],\n",
       "                         'tfidf__smooth_idf': [False, True]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For label related this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.34      0.04      0.07      2042\n",
      "         1.0       0.76      0.98      0.85      6546\n",
      "         2.0       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.75      8649\n",
      "   macro avg       0.37      0.34      0.31      8649\n",
      "weighted avg       0.65      0.75      0.66      8649\n",
      "\n",
      "For label request this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.99      0.91      7194\n",
      "         1.0       0.47      0.05      0.09      1455\n",
      "\n",
      "    accuracy                           0.83      8649\n",
      "   macro avg       0.65      0.52      0.50      8649\n",
      "weighted avg       0.78      0.83      0.77      8649\n",
      "\n",
      "For label offer this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8615\n",
      "         1.0       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           1.00      8649\n",
      "   macro avg       0.50      0.50      0.50      8649\n",
      "weighted avg       0.99      1.00      0.99      8649\n",
      "\n",
      "For label aid_related this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.86      0.71      5133\n",
      "         1.0       0.47      0.18      0.26      3516\n",
      "\n",
      "    accuracy                           0.59      8649\n",
      "   macro avg       0.54      0.52      0.49      8649\n",
      "weighted avg       0.55      0.59      0.53      8649\n",
      "\n",
      "For label medical_help this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96      7984\n",
      "         1.0       0.00      0.00      0.00       665\n",
      "\n",
      "    accuracy                           0.92      8649\n",
      "   macro avg       0.46      0.50      0.48      8649\n",
      "weighted avg       0.85      0.92      0.89      8649\n",
      "\n",
      "For label medical_products this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      8242\n",
      "         1.0       0.00      0.00      0.00       407\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.91      0.95      0.93      8649\n",
      "\n",
      "For label search_and_rescue this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99      8415\n",
      "         1.0       0.14      0.00      0.01       234\n",
      "\n",
      "    accuracy                           0.97      8649\n",
      "   macro avg       0.56      0.50      0.50      8649\n",
      "weighted avg       0.95      0.97      0.96      8649\n",
      "\n",
      "For label security this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8479\n",
      "         1.0       0.00      0.00      0.00       170\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.49      0.50      0.49      8649\n",
      "weighted avg       0.96      0.98      0.97      8649\n",
      "\n",
      "For label military this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      8366\n",
      "         1.0       0.00      0.00      0.00       283\n",
      "\n",
      "    accuracy                           0.97      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.94      0.97      0.95      8649\n",
      "\n",
      "For label child_alone this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8649\n",
      "\n",
      "    accuracy                           1.00      8649\n",
      "   macro avg       1.00      1.00      1.00      8649\n",
      "weighted avg       1.00      1.00      1.00      8649\n",
      "\n",
      "For label water this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97      8127\n",
      "         1.0       0.00      0.00      0.00       522\n",
      "\n",
      "    accuracy                           0.94      8649\n",
      "   macro avg       0.47      0.50      0.48      8649\n",
      "weighted avg       0.88      0.94      0.91      8649\n",
      "\n",
      "For label food this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.94      7740\n",
      "         1.0       0.20      0.00      0.01       909\n",
      "\n",
      "    accuracy                           0.89      8649\n",
      "   macro avg       0.55      0.50      0.48      8649\n",
      "weighted avg       0.82      0.89      0.85      8649\n",
      "\n",
      "For label shelter this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95      7865\n",
      "         1.0       0.03      0.00      0.00       784\n",
      "\n",
      "    accuracy                           0.91      8649\n",
      "   macro avg       0.47      0.50      0.48      8649\n",
      "weighted avg       0.83      0.91      0.86      8649\n",
      "\n",
      "For label clothing this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8513\n",
      "         1.0       0.00      0.00      0.00       136\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.97      0.98      0.98      8649\n",
      "\n",
      "For label money this is the result.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8452\n",
      "         1.0       0.14      0.01      0.01       197\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.56      0.50      0.50      8649\n",
      "weighted avg       0.96      0.98      0.97      8649\n",
      "\n",
      "For label missing_people this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      8544\n",
      "         1.0       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.98      0.99      0.98      8649\n",
      "\n",
      "For label refugees this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      8319\n",
      "         1.0       0.00      0.00      0.00       330\n",
      "\n",
      "    accuracy                           0.96      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.93      0.96      0.94      8649\n",
      "\n",
      "For label death this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98      8255\n",
      "         1.0       0.00      0.00      0.00       394\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.91      0.95      0.93      8649\n",
      "\n",
      "For label other_aid this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93      7554\n",
      "         1.0       0.10      0.01      0.01      1095\n",
      "\n",
      "    accuracy                           0.87      8649\n",
      "   macro avg       0.49      0.50      0.47      8649\n",
      "weighted avg       0.78      0.87      0.81      8649\n",
      "\n",
      "For label infrastructure_related this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.97      8081\n",
      "         1.0       0.09      0.00      0.00       568\n",
      "\n",
      "    accuracy                           0.93      8649\n",
      "   macro avg       0.51      0.50      0.48      8649\n",
      "weighted avg       0.88      0.93      0.90      8649\n",
      "\n",
      "For label transport this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98      8247\n",
      "         1.0       0.00      0.00      0.00       402\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.91      0.95      0.93      8649\n",
      "\n",
      "For label buildings this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      8202\n",
      "         1.0       0.14      0.01      0.02       447\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.55      0.50      0.49      8649\n",
      "weighted avg       0.91      0.95      0.92      8649\n",
      "\n",
      "For label electricity this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8473\n",
      "         1.0       0.00      0.00      0.00       176\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.49      0.50      0.49      8649\n",
      "weighted avg       0.96      0.98      0.97      8649\n",
      "\n",
      "For label tools this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      8603\n",
      "         1.0       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.50      0.50      0.50      8649\n",
      "weighted avg       0.99      0.99      0.99      8649\n",
      "\n",
      "For label hospitals this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      8553\n",
      "         1.0       0.00      0.00      0.00        96\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.98      0.99      0.98      8649\n",
      "\n",
      "For label shops this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      8607\n",
      "         1.0       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           1.00      8649\n",
      "   macro avg       0.50      0.50      0.50      8649\n",
      "weighted avg       0.99      1.00      0.99      8649\n",
      "\n",
      "For label aid_centers this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      8542\n",
      "         1.0       0.00      0.00      0.00       107\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.98      0.99      0.98      8649\n",
      "\n",
      "For label other_infrastructure this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98      8263\n",
      "         1.0       0.00      0.00      0.00       386\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.91      0.95      0.93      8649\n",
      "\n",
      "For label weather_related this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.97      0.84      6256\n",
      "         1.0       0.60      0.13      0.22      2393\n",
      "\n",
      "    accuracy                           0.74      8649\n",
      "   macro avg       0.67      0.55      0.53      8649\n",
      "weighted avg       0.71      0.74      0.67      8649\n",
      "\n",
      "For label floods this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      1.00      0.96      7940\n",
      "         1.0       0.10      0.00      0.00       709\n",
      "\n",
      "    accuracy                           0.92      8649\n",
      "   macro avg       0.51      0.50      0.48      8649\n",
      "weighted avg       0.85      0.92      0.88      8649\n",
      "\n",
      "For label storm this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      1.00      0.95      7815\n",
      "         1.0       0.39      0.03      0.05       834\n",
      "\n",
      "    accuracy                           0.90      8649\n",
      "   macro avg       0.65      0.51      0.50      8649\n",
      "weighted avg       0.86      0.90      0.86      8649\n",
      "\n",
      "For label fire this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      8563\n",
      "         1.0       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.99      8649\n",
      "   macro avg       0.50      0.50      0.50      8649\n",
      "weighted avg       0.98      0.99      0.99      8649\n",
      "\n",
      "For label earthquake this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.99      0.95      7836\n",
      "         1.0       0.73      0.15      0.25       813\n",
      "\n",
      "    accuracy                           0.92      8649\n",
      "   macro avg       0.82      0.57      0.60      8649\n",
      "weighted avg       0.90      0.92      0.89      8649\n",
      "\n",
      "For label cold this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      8482\n",
      "         1.0       0.00      0.00      0.00       167\n",
      "\n",
      "    accuracy                           0.98      8649\n",
      "   macro avg       0.49      0.50      0.50      8649\n",
      "weighted avg       0.96      0.98      0.97      8649\n",
      "\n",
      "For label other_weather this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97      8226\n",
      "         1.0       0.00      0.00      0.00       423\n",
      "\n",
      "    accuracy                           0.95      8649\n",
      "   macro avg       0.48      0.50      0.49      8649\n",
      "weighted avg       0.90      0.95      0.93      8649\n",
      "\n",
      "For label direct_report this is the result.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.99      0.89      6987\n",
      "         1.0       0.42      0.04      0.07      1662\n",
      "\n",
      "    accuracy                           0.81      8649\n",
      "   macro avg       0.61      0.51      0.48      8649\n",
      "weighted avg       0.74      0.81      0.73      8649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = cv.predict(X_test)\n",
    "y_pred = pd.DataFrame(y_pred, columns = df.columns[4:])\n",
    "for i, var in enumerate(df.columns[4:]):\n",
    "    print(\"For label \" + var + \" this is the result.\")\n",
    "    print(classification_report(y_test.iloc[:,i], \n",
    "                                y_pred.iloc[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__n_estimators': 30,\n",
       " 'clf__estimator__n_jobs': 2,\n",
       " 'tfidf__smooth_idf': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                                                                        ccp_alpha=0.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        max_samples=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=30,\n",
       "                                                                        n_jobs=2,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=None,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
